# -*- coding: utf-8 -*-
"""AutoencodersRuido.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iim6y0EcyJHa7hnnDY3lGcNlNDCeXgG8
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import cv2
import random

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5), (0.5))
    ])
transform = transforms.ToTensor()

mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)

data_loader = torch.utils.data.DataLoader(dataset=mnist_data,batch_size=64,shuffle=True)

mnist_data_valid = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

data_loader_valid = torch.utils.data.DataLoader(dataset=mnist_data_valid,batch_size=64, shuffle=True)



dataiter = iter(data_loader) #Convierte el DataLoader en un iterador lo que te permite recorrer el conjunto de datos por lotes.
images, labels = next(dataiter)
print(torch.min(images), torch.max(images))


class Autoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        # N, 1, 28, 28
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, 3, stride=2, padding=1), # -> N, 16, 14, 14
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, stride=2, padding=1), # -> N, 32, 7, 7
            nn.ReLU(),
            nn.Conv2d(32, 64, 7) # -> N, 64, 1, 1
        )

        # N , 64, 1, 1
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, 7), # -> N, 32, 7, 7
            nn.ReLU(),
            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # N, 16, 14, 14
            nn.ReLU(),
            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), # N, 1, 28, 28
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

model = Autoencoder()

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)

#Añadimos Ruido
def add_gaussian_noise(images, mean=0.2, var=0.5):
    noisy_images = torch.clone(images)
    sigma = np.sqrt(var)
    # Generar ruido gaussiano
    noise = torch.randn_like(noisy_images) * sigma + mean

    # Añadir el ruido a las imágenes
    noisy_images += noise

    # Asegurar que los valores estén en el rango [0, 1]
    noisy_images = torch.clamp(noisy_images, 0, 1)

    return noisy_images

def add_uniform_noise(images, a=0, b=0.7):
    noisy_images = torch.clone(images)
    batch_size, num_channels, x, y = images.size()
    noise = torch.FloatTensor(batch_size, num_channels, x, y).uniform_(a, b)
    noisy_images += noise
    noisy_images = torch.clamp(noisy_images, 0, 1)  # Asegura que los valores estén en el rango [0, 1]
    return noisy_images


def add_salt_and_pepper_noise(images, salt_prob=0.2): #Pepper porcentaje de puntos que queremos en la imagen
    noisy_images = torch.clone(images)
    _, c, x, y = images.size()
    pepper_prob = 1 - salt_prob

    for i in range(x):
        for j in range(y):
            rdn = np.random.random()
            if rdn > pepper_prob:
                noisy_images[:, :, i, j] = 0  # Píxel negro (pepper)
            elif rdn < salt_prob:
                noisy_images[:, :, i, j] = 1  # Píxel blanco (salt)
            # Si rdn está entre pepper_prob y salt_prob, no se realiza ningún cambio (píxel original)

    return noisy_images

#Para mostrar imagenes con ruido
def show_images_with_noise(images, noisy_images, num_images=9):
    plt.figure(figsize=(9, 2))
    plt.gray()

    for i in range(num_images):
        plt.subplot(2, num_images, i + 1)
        plt.imshow(images[i][0])
        plt.title("Original")

        plt.subplot(2, num_images, num_images + i + 1)
        plt.imshow(noisy_images[i][0])
        plt.title("Noisy")

    plt.show()

# training
num_epochs = 4
outputs = []
for epoch in range(num_epochs):
    for (images, _) in data_loader:

        noisy_images = add_gaussian_noise(images)

        images_original = images.reshape(-1, 1,28,28) # -> use for Autoencoder

        recon = model(noisy_images)
        loss = criterion(recon, images_original)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')
    outputs.append((epoch, images_original, recon))

    show_images_with_noise(images_original, noisy_images)

#Crea las imagenes
for k in range(0, num_epochs, 4):
    plt.figure(figsize=(9, 2))
    plt.gray()
    imgs = outputs[k][1].detach().numpy()
    recon = outputs[k][2].detach().numpy()
    for i, item in enumerate(imgs):
        if i >= 9: break
        plt.subplot(2, 9, i+1)
        item = item.reshape(-1, 28,28) # -> use for Autoencoder_Linear
        # item: 1, 28, 28
        plt.imshow(item[0])

    for i, item in enumerate(recon):
        if i >= 9: break
        plt.subplot(2, 9, 9+i+1) # row_length + i + 1
        item = item.reshape(-1, 28,28) # -> use for Autoencoder_Linear
        # item: 1, 28, 28
        plt.imshow(item[0])

#Evalución
model.eval()

dataiter = iter(data_loader_valid) #Convierte el data_loader_valid en un iterador lo que te permite recorrer el conjunto de datos por lotes.
images, labels = next(dataiter)
img = images[0]

plt.figure(figsize=(9, 2))
plt.gray()


for i, img in enumerate(images[:9]):
    with torch.no_grad():
        noisy_images = add_gaussian_noise(images)  # Aplicar ruido a las imágenes para la evaluación
        noisy_img = noisy_images[i].reshape(-1, 1, 28, 28)  # Asegurarse de que la entrada ruidosa tenga la forma correcta
        pred = model(noisy_img)
        recon = pred[0].detach().numpy()
        recon2 = recon.reshape(-1, 28,28) # -> use for Autoencoder_Linear

        plt.subplot(2, 9, i+1)
        plt.imshow(img[0])

        plt.subplot(2, 9, i+1+9)
        plt.imshow(recon2[0])